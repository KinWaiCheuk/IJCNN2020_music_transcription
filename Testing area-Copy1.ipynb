{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-da2d879c69ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tp'"
     ]
    }
   ],
   "source": [
    "import os,sys,signal\n",
    "import math\n",
    "\n",
    "import pickle\n",
    "import numpy as np                                       # fast vectors and matrices\n",
    "import matplotlib.pyplot as plt                          # plotting\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import musicnet\n",
    "\n",
    "from time import time\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'   # see issue #152\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='2'\n",
    "\n",
    "import torch\n",
    "from torch.nn.functional import conv1d, mse_loss\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "import tp\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "train_size = 100000\n",
    "test_size = 50000\n",
    "epsilon = 1e-5\n",
    "fs = 44100\n",
    "\n",
    "lr = 1e-6\n",
    "momentum = .95\n",
    "\n",
    "pitch_shift = 0\n",
    "jitter = 0.\n",
    "num_workers = 10\n",
    "sequence = 1\n",
    "\n",
    "# lvl1 convolutions are shared between regions\n",
    "m = 128\n",
    "k = 512              # lvl1 nodes\n",
    "n_fft = 4096              # lvl1 receptive field\n",
    "window = 16384 # total number of audio samples?\n",
    "stride = 512\n",
    "batch_size = 100\n",
    "freq_bins = 2049\n",
    "\n",
    "regions = 1 + (window)//stride\n",
    "\n",
    "def worker_init(args):\n",
    "    signal.signal(signal.SIGINT, signal.SIG_IGN) # ignore signals so parent can handle them\n",
    "    np.random.seed(os.getpid() ^ int(time())) # approximately random seed for workers\n",
    "kwargs = {'num_workers': num_workers, 'pin_memory': True, 'worker_init_fn': worker_init}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for returning scientific notation in a plot\n",
    "def fmt(x, pos):\n",
    "    a, b = '{:.0e}'.format(x).split('e')\n",
    "    b = int(b)\n",
    "    return fr'${a} \\times 10^{{{b}}}$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {'loss_history_train': [],\n",
    "               'avgp_history_train': [],\n",
    "               'loss_history_test': [],\n",
    "               'avgp_history_test': [],\n",
    "               \"Mir_Eval\": [],\n",
    "               'parameters': {}}\n",
    "\n",
    "result_dict['parameters']['train_size'] = train_size\n",
    "result_dict['parameters']['test_size'] = test_size\n",
    "result_dict['parameters']['lr'] = lr\n",
    "result_dict['parameters']['pitch_shift'] = pitch_shift\n",
    "result_dict['parameters']['jitter'] = jitter\n",
    "result_dict['parameters']['window'] = window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded, time used = 28.36 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "root = './data/'\n",
    "train_set = musicnet.MusicNet(root=root, epoch_size=train_size,sequence=sequence\n",
    "                              , train=True, download=True, refresh_cache=False, \n",
    "                              window=window, mmap=False, pitch_shift=pitch_shift, jitter=jitter)\n",
    "test_set = musicnet.MusicNet(root=root, train=False, download=True,sequence=sequence\n",
    "                             , refresh_cache=False, window=window, epoch_size=test_size, mmap=False)\n",
    "print(\"Data loaded, time used = {:2.2f} seconds\".format(time()-start))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_set,batch_size=batch_size,**kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set,batch_size=batch_size,**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss = torch.nn.BCELoss()\n",
    "def L(yhatvar,y):\n",
    "    return Loss(yhatvar,y) * 128/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mels=1024\n",
    "htk=True\n",
    "center=True\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, avg=.9998):\n",
    "        super(Model, self).__init__()\n",
    "        # Getting Mel Spectrogram on the fly\n",
    "        self.mel_layer = Spectrogram.MelSpectrogram(sr=fs, n_fft=n_fft, n_mels=n_mels, htk=htk, fmin=50, fmax=6000, center=center, trainable_mel=False)\n",
    "            \n",
    "        # Creating Layers\n",
    "        self.linear = torch.nn.Linear(n_mels*regions, m, bias=False)\n",
    "        torch.nn.init.constant_(self.linear.weight, 0) # initialize\n",
    "        \n",
    "        self.avg = avg\n",
    "        \n",
    "    def forward(self,x):\n",
    "        z = self.mel_layer(x)\n",
    "        z = torch.relu(z)\n",
    "        y = self.linear((torch.log(z+epsilon)).view(x.data.size()[0],n_mels*regions))\n",
    "        return torch.sigmoid(y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/public_data/raven/ICASSP2020/Spectrogram.py:578: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  warnings.warn('Empty filters detected in mel frequency basis. '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (mel_layer): MelSpectrogram()\n",
       "  (linear): Linear(in_features=33792, out_features=128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch\ttrain loss\ttest loss\ttrain avg\ttest avg\ttime\tutime\n",
      "0\t5.046527\t3.426358\t0.204624\t0.432643\t126.0\t40.2\n",
      "1\t3.813747\t2.854614\t0.509571\t0.513225\t126.0\t40.0\n",
      "2\t3.361868\t2.622244\t0.560346\t0.550316\t125.6\t40.6\n",
      "3\t3.152200\t2.473923\t0.589096\t0.571610\t126.1\t40.5\n",
      "4\t3.034464\t2.404543\t0.605886\t0.583332\t124.8\t40.5\n",
      "5\t2.950832\t2.347562\t0.619306\t0.600089\t125.7\t40.6\n",
      "6\t2.896505\t2.310350\t0.626848\t0.604606\t126.6\t40.9\n",
      "7\t2.845218\t2.250624\t0.636156\t0.618264\t126.5\t40.7\n",
      "8\t2.816717\t2.228036\t0.641739\t0.622007\t125.7\t40.5\n",
      "9\t2.791557\t2.208391\t0.642977\t0.628357\t125.3\t40.6\n",
      "10\t2.782295\t2.199435\t0.646430\t0.632072\t126.4\t40.5\n",
      "11\t2.760400\t2.168173\t0.649868\t0.636648\t126.3\t40.7\n",
      "Graceful Exit1000 batches\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "epochs = 35\n",
    "try:\n",
    "    with train_set, test_set:\n",
    "        print(\"epoch\\ttrain loss\\ttest loss\\ttrain avg\\ttest avg\\ttime\\tutime\")\n",
    "        for e in range(epochs):\n",
    "            yground = torch.Tensor(batch_size*len(train_loader), m) # what not do this together with loss\n",
    "            yhat = torch.Tensor(batch_size*len(train_loader), m)\n",
    "            avgp, loss_e = 0.,0\n",
    "            t = time()\n",
    "            for i, (x,y) in enumerate(train_loader):\n",
    "                print(f\"training {i}/{len(train_loader)} batches\", end = '\\r')\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # making x and y into pytorch dealable format\n",
    "                x = x.to(device, non_blocking=True)\n",
    "                y = y.to(device, non_blocking=True)\n",
    "                yhatvar = model(x)\n",
    "                loss = L(yhatvar,y)\n",
    "                loss.backward()\n",
    "                loss_e += loss.item() #getting the number\n",
    "\n",
    "                yground[i*batch_size:(i+1)*batch_size] = y.data\n",
    "                yhat[i*batch_size:(i+1)*batch_size] = yhatvar.data\n",
    "\n",
    "                optimizer.step()\n",
    "            avgp = average_precision_score(yground.cpu().flatten(),yhat.cpu().flatten())  \n",
    "\n",
    "            result_dict['loss_history_train'].append(loss_e/len(train_loader))\n",
    "            result_dict['avgp_history_train'].append(avgp)   \n",
    "            t1 = time()\n",
    "            avgp, loss_e = 0.,0.           \n",
    "#             optimizer.swap_swa_sgd() # change to average weight\n",
    "\n",
    "            # For testing\n",
    "            yground = torch.Tensor(batch_size*len(test_loader), m) # what not do this together with loss\n",
    "            yhat = torch.Tensor(batch_size*len(test_loader), m)\n",
    "\n",
    "            for i, (x_test,y_test) in enumerate(test_loader):\n",
    "                print(f\"testing {i}/{len(test_loader)} batches\", end = '\\r')\n",
    "                x_test = x_test.to(device)\n",
    "                y_test = y_test.to(device)\n",
    "                yhatvar = model(x_test)\n",
    "                loss_e += L(yhatvar, y_test).item() #getting the number\n",
    "\n",
    "                yground[i*batch_size:(i+1)*batch_size] = y_test.data\n",
    "                yhat[i*batch_size:(i+1)*batch_size] = yhatvar.data\n",
    "            avgp = average_precision_score(yground.cpu().flatten(),yhat.cpu().flatten())\n",
    "            result_dict['loss_history_test'].append(loss_e/len(test_loader))\n",
    "            result_dict['avgp_history_test'].append(avgp)\n",
    "            print('{}\\t{:2f}\\t{:2f}\\t{:2f}\\t{:2f}\\t{:2.1f}\\t{:2.1f}'.\\\n",
    "                  format(e,\n",
    "                         result_dict['loss_history_train'][-1],result_dict['loss_history_test'][-1],\n",
    "                         result_dict['avgp_history_train'][-1],result_dict['avgp_history_test'][-1],\n",
    "                         time()-t, time()-t1))\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('Graceful Exit')\n",
    "else:\n",
    "    print(\"Finsihed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.mel_layer = Spectrogram.MelSpectrogram(sr=fs, n_fft=n_fft, n_mels=n_mels, htk=htk, fmin=50, fmax=6000, center=center, trainable_mel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch\ttrain loss\ttest loss\ttrain avg\ttest avg\ttime\tutime\n",
      "0\t2.600988\t2.097811\t0.680068\t0.660468\t134.6\t40.7\n",
      "1\t2.571981\t2.094215\t0.683089\t0.659492\t134.3\t40.6\n",
      "2\t2.527469\t2.075081\t0.690801\t0.661859\t133.3\t40.7\n",
      "3\t2.515940\t2.046237\t0.693066\t0.669303\t133.7\t40.5\n",
      "4\t2.509748\t2.048616\t0.694715\t0.666293\t134.1\t40.7\n",
      "5\t2.498005\t2.043643\t0.696375\t0.672975\t133.8\t40.6\n",
      "6\t2.489267\t2.053690\t0.697824\t0.667427\t133.2\t40.2\n",
      "7\t2.487893\t2.033627\t0.700363\t0.673408\t132.5\t40.7\n",
      "8\t2.490052\t2.040657\t0.698489\t0.676443\t133.7\t40.9\n",
      "9\t2.473646\t2.013848\t0.700644\t0.679649\t134.6\t40.4\n",
      "10\t2.462775\t2.031345\t0.702213\t0.674480\t134.9\t40.6\n",
      "11\t2.456518\t2.057388\t0.704515\t0.670516\t133.4\t39.5\n",
      "12\t2.444676\t2.040432\t0.707598\t0.672726\t134.1\t39.9\n",
      "13\t2.440036\t2.015620\t0.707663\t0.674608\t134.5\t40.6\n",
      "14\t2.441463\t2.017350\t0.708049\t0.682218\t134.2\t40.5\n",
      "15\t2.426665\t2.029547\t0.709868\t0.678253\t133.2\t40.2\n",
      "16\t2.423350\t2.034943\t0.710561\t0.675934\t132.9\t39.2\n",
      "17\t2.417891\t2.001416\t0.710667\t0.680752\t133.5\t39.8\n",
      "18\t2.407763\t2.003435\t0.713648\t0.678817\t134.0\t40.6\n",
      "19\t2.411994\t2.003346\t0.711325\t0.680610\t134.6\t40.7\n",
      "20\t2.410161\t2.000709\t0.712527\t0.685885\t134.5\t40.7\n",
      "21\t2.415299\t2.012918\t0.713447\t0.686149\t133.5\t40.7\n",
      "22\t2.398606\t1.986423\t0.715270\t0.683503\t133.7\t40.5\n",
      "23\t2.389102\t2.002008\t0.716921\t0.683049\t134.1\t40.2\n",
      "24\t2.408906\t2.009663\t0.714452\t0.683624\t135.2\t40.8\n",
      "25\t2.382448\t2.003248\t0.717131\t0.681307\t134.4\t40.8\n",
      "26\t2.378231\t2.008558\t0.719722\t0.681274\t133.9\t40.6\n",
      "27\t2.369848\t1.975566\t0.720940\t0.687737\t134.4\t40.7\n",
      "28\t2.376248\t2.021250\t0.720291\t0.679009\t134.0\t40.3\n",
      "29\t2.373498\t1.996148\t0.721709\t0.680476\t133.7\t40.4\n",
      "30\t2.373668\t1.965097\t0.719257\t0.686829\t134.3\t40.7\n",
      "31\t2.369369\t1.999821\t0.719975\t0.683776\t133.6\t40.6\n",
      "32\t2.368513\t1.995949\t0.721351\t0.683989\t133.4\t40.4\n",
      "33\t2.355677\t2.012174\t0.722780\t0.684207\t134.2\t40.7\n",
      "34\t2.353941\t1.993800\t0.723413\t0.685138\t134.2\t40.5\n",
      "Finsihed\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "epochs = 35\n",
    "try:\n",
    "    with train_set, test_set:\n",
    "        print(\"epoch\\ttrain loss\\ttest loss\\ttrain avg\\ttest avg\\ttime\\tutime\")\n",
    "        for e in range(epochs):\n",
    "            yground = torch.Tensor(batch_size*len(train_loader), m) # what not do this together with loss\n",
    "            yhat = torch.Tensor(batch_size*len(train_loader), m)\n",
    "            avgp, loss_e = 0.,0\n",
    "            t = time()\n",
    "            for i, (x,y) in enumerate(train_loader):\n",
    "                print(f\"training {i}/{len(train_loader)} batches\", end = '\\r')\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # making x and y into pytorch dealable format\n",
    "                x = x.to(device, non_blocking=True)\n",
    "                y = y.to(device, non_blocking=True)\n",
    "                yhatvar = model(x)\n",
    "                loss = L(yhatvar,y)\n",
    "                loss.backward()\n",
    "                loss_e += loss.item() #getting the number\n",
    "\n",
    "                yground[i*batch_size:(i+1)*batch_size] = y.data\n",
    "                yhat[i*batch_size:(i+1)*batch_size] = yhatvar.data\n",
    "\n",
    "                optimizer.step()\n",
    "            avgp = average_precision_score(yground.cpu().flatten(),yhat.cpu().flatten())  \n",
    "\n",
    "            result_dict['loss_history_train'].append(loss_e/len(train_loader))\n",
    "            result_dict['avgp_history_train'].append(avgp)   \n",
    "            t1 = time()\n",
    "            avgp, loss_e = 0.,0.           \n",
    "#             optimizer.swap_swa_sgd() # change to average weight\n",
    "\n",
    "            # For testing\n",
    "            yground = torch.Tensor(batch_size*len(test_loader), m) # what not do this together with loss\n",
    "            yhat = torch.Tensor(batch_size*len(test_loader), m)\n",
    "\n",
    "            for i, (x_test,y_test) in enumerate(test_loader):\n",
    "                print(f\"testing {i}/{len(test_loader)} batches\", end = '\\r')\n",
    "                x_test = x_test.to(device)\n",
    "                y_test = y_test.to(device)\n",
    "                yhatvar = model(x_test)\n",
    "                loss_e += L(yhatvar, y_test).item() #getting the number\n",
    "\n",
    "                yground[i*batch_size:(i+1)*batch_size] = y_test.data\n",
    "                yhat[i*batch_size:(i+1)*batch_size] = yhatvar.data\n",
    "            avgp = average_precision_score(yground.cpu().flatten(),yhat.cpu().flatten())\n",
    "            result_dict['loss_history_test'].append(loss_e/len(test_loader))\n",
    "            result_dict['avgp_history_test'].append(avgp)\n",
    "            print('{}\\t{:2f}\\t{:2f}\\t{:2f}\\t{:2f}\\t{:2.1f}\\t{:2.1f}'.\\\n",
    "                  format(e,\n",
    "                         result_dict['loss_history_train'][-1],result_dict['loss_history_test'][-1],\n",
    "                         result_dict['avgp_history_train'][-1],result_dict['avgp_history_test'][-1],\n",
    "                         time()-t, time()-t1))\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('Graceful Exit')\n",
    "else:\n",
    "    print(\"Finsihed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_basis = model.mel_layer.mel_basis.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 2049)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel_basis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counter = 0\n",
    "for i in mel_basis:\n",
    "    plt.plot(i[:50])\n",
    "    if counter == 10:\n",
    "        break\n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AvgP\tP\tR\tAcc\tETot\tESub\tEmiss\tEfa\n",
      "75.24\t73.17\t70.82\t0.56\t0.43\t0.12\t0.17\t0.14        \n",
      "76.54\t72.77\t71.98\t0.57\t0.46\t0.09\t0.19\t0.18        \n",
      "44.64\t53.62\t41.12\t0.30\t0.77\t0.18\t0.41\t0.18        \n",
      "63.80\t58.11\t71.71\t0.47\t0.70\t0.10\t0.19\t0.42        \n",
      "75.87\t65.93\t82.25\t0.58\t0.46\t0.14\t0.04\t0.29        \n",
      "72.50\t65.96\t70.87\t0.52\t0.51\t0.15\t0.14\t0.22        \n",
      "66.58\t69.20\t57.57\t0.46\t0.53\t0.15\t0.28\t0.11        \n",
      "67.23\t66.36\t61.77\t0.47\t0.55\t0.15\t0.24\t0.17        \n",
      "75.33\t72.85\t68.28\t0.54\t0.47\t0.10\t0.22\t0.15        \n",
      "69.94\t67.27\t71.05\t0.53\t0.51\t0.13\t0.16\t0.22        \n",
      "Average Accuracy: \t50.02\n",
      "Average Error: \t\t53.89\n"
     ]
    }
   ],
   "source": [
    "print('AvgP\\tP\\tR\\tAcc\\tETot\\tESub\\tEmiss\\tEfa')\n",
    "Accavg = 0\n",
    "Etotavg = 0\n",
    "model.eval()\n",
    "for songid in test_set.rec_ids:\n",
    "    Y_pred, Y_true = musicnet.get_piano_roll(songid, test_set, model, device,\n",
    "                                             window=window, m=m, stride=-1)\n",
    "    _,_,_,Acc,Etot = musicnet.get_mir_accuracy(Y_pred, Y_true, m=m)\n",
    "    Accavg += Acc\n",
    "    Etotavg += Etot\n",
    "    result_dict['Mir_Eval'].append([Acc, Etot])\n",
    "\n",
    "print('Average Accuracy: \\t{:2.2f}\\nAverage Error: \\t\\t{:2.2f}'\n",
    "      .format(Accavg/len(test_set.rec_ids)*100, Etotavg/len(test_set.rec_ids)*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
